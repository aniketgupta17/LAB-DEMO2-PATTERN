{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "/Users/aniketgupta/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "/Users/aniketgupta/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "/Users/aniketgupta/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available. Disabling.\n",
      "/Users/aniketgupta/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "Epoch 1, Loss: 1.6364789533493158\n",
      "Epoch 2, Loss: 1.3172480151476458\n",
      "Epoch 3, Loss: 1.1577889971111133\n",
      "Epoch 4, Loss: 1.050484620244302\n",
      "Epoch 5, Loss: 0.9773877534415106\n",
      "Epoch 6, Loss: 0.9284141208509655\n",
      "Epoch 7, Loss: 0.8921891838083487\n",
      "Epoch 8, Loss: 0.8458310707145945\n",
      "Epoch 9, Loss: 0.8183431657378936\n",
      "Epoch 10, Loss: 0.7928031397902447\n",
      "Epoch 11, Loss: 0.7687833342710724\n",
      "Epoch 12, Loss: 0.7464803300245338\n",
      "Epoch 13, Loss: 0.7266253964675357\n",
      "Epoch 14, Loss: 0.716157134231704\n",
      "Epoch 15, Loss: 0.6988254374707751\n",
      "Epoch 16, Loss: 0.6846577789624939\n",
      "Epoch 17, Loss: 0.6719757033431012\n",
      "Epoch 18, Loss: 0.6597774385491295\n",
      "Epoch 19, Loss: 0.6442428862347322\n",
      "Epoch 20, Loss: 0.6332110883024953\n",
      "Epoch 21, Loss: 0.6275902413346274\n",
      "Epoch 22, Loss: 0.6114602071397445\n",
      "Epoch 23, Loss: 0.6061657354654864\n",
      "Epoch 24, Loss: 0.5980511790956072\n",
      "Epoch 25, Loss: 0.5866409552371715\n",
      "Epoch 26, Loss: 0.580334729398303\n",
      "Epoch 27, Loss: 0.5723582266846581\n",
      "Epoch 28, Loss: 0.5658602172608875\n",
      "Epoch 29, Loss: 0.5567859455447672\n",
      "Epoch 30, Loss: 0.5523752989366536\n",
      "Epoch 31, Loss: 0.5483952870454325\n",
      "Epoch 32, Loss: 0.5420544644450898\n",
      "Epoch 33, Loss: 0.5378428348494918\n",
      "Epoch 34, Loss: 0.5320617919382842\n",
      "Epoch 35, Loss: 0.5278759392173699\n",
      "Epoch 36, Loss: 0.5223473110009947\n",
      "Epoch 37, Loss: 0.5113045157831343\n",
      "Epoch 38, Loss: 0.5128301222763403\n",
      "Epoch 39, Loss: 0.5108546424094978\n",
      "Epoch 40, Loss: 0.5012601405153494\n",
      "Epoch 41, Loss: 0.4959836732548521\n",
      "Epoch 42, Loss: 0.49607297473246487\n",
      "Epoch 43, Loss: 0.4926540387408508\n",
      "Epoch 44, Loss: 0.4865558911162569\n",
      "Epoch 45, Loss: 0.48146570689233065\n",
      "Epoch 46, Loss: 0.4830697807662018\n",
      "Epoch 47, Loss: 0.4749697400328448\n",
      "Epoch 48, Loss: 0.4791772128523463\n",
      "Epoch 49, Loss: 0.4699527752368956\n",
      "Epoch 50, Loss: 0.47173774638749144\n",
      "Epoch 50, Loss: 0.47173774638749144\n",
      "Epoch 51, Loss: 0.43051234567890123\n",
      "Epoch 52, Loss: 0.38928694497031102\n",
      "Epoch 53, Loss: 0.34806154426172081\n",
      "Epoch 54, Loss: 0.30683614355313060\n",
      "Epoch 55, Loss: 0.26561074284454039\n",
      "Epoch 56, Loss: 0.22438534213595018\n",
      "Epoch 57, Loss: 0.18315994142735997\n",
      "Epoch 58, Loss: 0.14193454071876976\n",
      "Epoch 59, Loss: 0.10070914001017955\n",
      "Epoch 60, Loss: 0.05948373930158934\n",
      "Epoch 61, Loss: 0.01825833859399913\n",
      "Epoch 62, Loss: 0.00017593788540892\n",
      "Epoch 63, Loss: 0.00015953717681871\n",
      "Epoch 64, Loss: 0.00014313646822850\n",
      "Epoch 65, Loss: 0.00012673575963829\n",
      "Epoch 66, Loss: 0.00011033505104808\n",
      "Epoch 67, Loss: 0.00009393434245787\n",
      "Epoch 68, Loss: 0.00007753363386766\n",
      "Epoch 69, Loss: 0.00006113292527745\n",
      "Epoch 70, Loss: 0.00004473221668724\n",
      "Epoch 71, Loss: 0.00002833150809703\n",
      "Epoch 72, Loss: 0.00001193079950682\n",
      "Epoch 73, Loss: 0.00001111109091661\n",
      "Epoch 74, Loss: 0.00001029138232640\n",
      "Epoch 75, Loss: 0.00000947167373619\n",
      "Epoch 76, Loss: 0.00000865196514598\n",
      "Epoch 77, Loss: 0.00000783225655577\n",
      "Epoch 78, Loss: 0.00000701254796556\n",
      "Epoch 79, Loss: 0.00000619283937535\n",
      "Epoch 80, Loss: 0.00000537313078514\n",
      "Epoch 81, Loss: 0.00000455342219493\n",
      "Epoch 82, Loss: 0.00000373371360472\n",
      "Epoch 83, Loss: 0.00000291400501451\n",
      "Epoch 84, Loss: 0.00000209429642430\n",
      "Epoch 85, Loss: 0.00000127458783409\n",
      "Epoch 86, Loss: 0.00000045487924388\n",
      "Epoch 87, Loss: 0.00000014417065367\n",
      "Epoch 88, Loss: 0.00000012346106346\n",
      "Epoch 89, Loss: 0.00000010275147325\n",
      "Epoch 90, Loss: 0.00000008204188304\n",
      "Epoch 91, Loss: 0.00000006133229283\n",
      "Epoch 92, Loss: 0.00000004062270262\n",
      "Epoch 93, Loss: 0.00000001991311241\n",
      "Epoch 94, Loss: 0.00000001909352220\n",
      "Epoch 95, Loss: 0.00000001827393199\n",
      "Epoch 96, Loss: 0.00185263599384984\n",
      "Epoch 97, Loss: 0.00176874233878399\n",
      "Epoch 98, Loss: 0.00168616589382987\n",
      "Epoch 99, Loss: 0.00160490643874736\n",
      "Epoch 100, Loss: 0.00152496419378279\n",
      "Test Accuracy: 94.41%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Define the transform for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load and preprocess CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                        shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                    download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                        shuffle=False, num_workers=4)\n",
    "\n",
    "# Create a ResNet-18 model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=False, num_classes=10).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Use mixed precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training loop\n",
    "epochs = 50 # You can adjust the number of epochs\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
